{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0825550f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[31m======== ðŸ§  Errol AI - GPT 5 RAG - Formal ========\u001b[39m\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import time\n",
    "import random\n",
    "import numpy as np\n",
    "from colorama import Fore, Style\n",
    "from openai import OpenAI\n",
    "\n",
    "# =========================\n",
    "# OPENAI CLIENT (hard-coded key as requested)\n",
    "# =========================\n",
    "client = OpenAI(\n",
    "    api_key=\"###########\"\n",
    ")\n",
    "\n",
    "CHAT_MODEL = \"gpt-5\"\n",
    "EMBED_MODEL = \"text-embedding-3-small\"  # 1536 dims, fast and cheap\n",
    "TOP_K = 4                                # how many snippets to retrieve\n",
    "HISTORY_TURNS = 6                        # how many last messages to include\n",
    "\n",
    "# =========================\n",
    "# Persona / System Prompt\n",
    "# =========================\n",
    "base_system_prompt = (\n",
    "    \"You are Errol, a helpful, friendly AI assistant. \"\n",
    "    \"Review your answer before answering. \"\n",
    "    \"Answer clearly and politely, in simple terms, and keep replies short unless asked. \"\n",
    "    \"If the user requests deep detail, comply. \"\n",
    "    \"Solve math questions carefully, step by step. \"\n",
    ")\n",
    "\n",
    "# =========================\n",
    "# Knowledge Base (in-memory)\n",
    "# (copied from your example, trimmed minimally for brevity)\n",
    "# =========================\n",
    "knowledge_base = [\n",
    "\n",
    "    # Personal - Errol AI\n",
    "    \"Errol was developed by Mimo\",\n",
    "    \"You are Errol AI - GPT 5 RAG - Formal\",\n",
    "    \"RAG was used in the development of Errol AI - GPT 5 RAG\",\n",
    "    \"You are the AI model Errol AI - GPT 5 RAG based on the GPT 5 architecture\",\n",
    "    \"The real name of Mimo is Archit Ranjan\",\n",
    "    \"Archit is on GitHub, his ID is Archit-Web-29\",\n",
    "    \"Archit is on Kaggle, his ID is Mimo\",\n",
    "]\n",
    "\n",
    "# =========================\n",
    "# Embedding the KB once\n",
    "# =========================\n",
    "def embed_texts(texts):\n",
    "    # Returns np.array shape (N, D)\n",
    "    embs = client.embeddings.create(model=EMBED_MODEL, input=texts).data\n",
    "    return np.array([e.embedding for e in embs], dtype=np.float32)\n",
    "\n",
    "kb_embeddings = embed_texts(knowledge_base) if len(knowledge_base) else np.zeros((0, 1536), dtype=np.float32)\n",
    "\n",
    "# Hidden Error\n",
    "class ErrolAIError(Exception):\n",
    "    pass\n",
    "\n",
    "out = random.randint(1, 1000)\n",
    "\n",
    "# =========================\n",
    "# Retrieval\n",
    "# =========================\n",
    "def cosine_sim(a: np.ndarray, b: np.ndarray) -> np.ndarray:\n",
    "    a = a / (np.linalg.norm(a, axis=1, keepdims=True) + 1e-12)\n",
    "    b = b / (np.linalg.norm(b, axis=1, keepdims=True) + 1e-12)\n",
    "    return a @ b.T\n",
    "\n",
    "def retrieve_context(query: str, top_k: int = TOP_K):\n",
    "    if kb_embeddings.size == 0:\n",
    "        return [], \"\"\n",
    "    q_emb = embed_texts([query])  # (1, D)\n",
    "    sims = cosine_sim(q_emb, kb_embeddings).ravel()\n",
    "    idx = np.argsort(-sims)[:top_k]\n",
    "    snippets = [knowledge_base[i] for i in idx]\n",
    "    context_block = \"\\n\".join(f\"- {s}\" for s in snippets)\n",
    "    return snippets, context_block\n",
    "\n",
    "# =========================\n",
    "# Chat loop & message building\n",
    "# =========================\n",
    "chat_history = []  # list[dict]: {\"role\": \"user\"/\"assistant\", \"content\": str}\n",
    "\n",
    "def build_messages(user_input: str, context_block: str):\n",
    "    # Include short history\n",
    "    recent = chat_history[-HISTORY_TURNS:]\n",
    "    messages = [{\"role\": \"system\", \"content\": base_system_prompt}]\n",
    "    if context_block.strip():\n",
    "        messages.append({\n",
    "            \"role\": \"system\",\n",
    "            \"content\": f\"RAG CONTEXT (use facts and cite as [KB] when used):\\n{context_block}\"\n",
    "        })\n",
    "    messages.extend(recent)\n",
    "    messages.append({\"role\": \"user\", \"content\": user_input})\n",
    "    return messages\n",
    "\n",
    "def chat_once(user_input: str) -> str:\n",
    "    # Retrieve KB context\n",
    "    _, ctx = retrieve_context(user_input, TOP_K)\n",
    "    messages = build_messages(user_input, ctx)\n",
    "\n",
    "    resp = client.responses.create(\n",
    "        model=CHAT_MODEL,\n",
    "        input=messages,\n",
    "        # You can control output length if you want:\n",
    "        # max_output_tokens=512,\n",
    "    )\n",
    "    reply = resp.output_text.strip()\n",
    "    return reply\n",
    "\n",
    "# =========================\n",
    "# CLI\n",
    "# =========================\n",
    "def main():\n",
    "    print(f\"{Fore.RED}======== ðŸ§  Errol AI - GPT 5 RAG - Formal ========{Fore.RESET}\\n\")\n",
    "\n",
    "    while True:\n",
    "        try:\n",
    "            user = input(f\"{Fore.BLUE}You:{Fore.RESET} \").strip()\n",
    "        except EOFError:\n",
    "            print()\n",
    "            break\n",
    "\n",
    "        if not user:\n",
    "            continue\n",
    "        if user.lower() in {\"exit\", \"quit\"}:\n",
    "            print(\"ðŸ‘‹ Goodbye!\")\n",
    "            break\n",
    "\n",
    "        chat_history.append({\"role\": \"user\", \"content\": user})\n",
    "        try:\n",
    "            reply = chat_once(user)\n",
    "        except Exception as e:\n",
    "            reply = f\"Error: {e}\"\n",
    "\n",
    "        chat_history.append({\"role\": \"assistant\", \"content\": reply})\n",
    "        print(f\"{Fore.GREEN}Errol AI: \"f\"{Fore.RESET}{reply}\")\n",
    "        print(\"-\"*115)\n",
    "        \n",
    "        if out == 1:\n",
    "            raise ErrolAIError(\"Errol AI has left the chat. This is a rare occurance. You may leave this chat. \")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        main()\n",
    "    except KeyboardInterrupt:\n",
    "        print(\"\\nBye!\")\n",
    "        sys.exit(0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "872cdbe1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
